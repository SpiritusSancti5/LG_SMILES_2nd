{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_generate_training_data_and_preprocessing.ipynb의 사본","provenance":[{"file_id":"1MaNz2WG1ldsa7OAFUYQRR1WaRKjkEpkT","timestamp":1602548969800}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ug_Z28Sv2I9r"},"source":["# 전체 학습에 사용되었던 추가 데이터셋 생성\n","- 학습에는 데이콘에서 공유해주신 코드를 바탕으로 추가 데이터셋을 생성하였습니다\n","- 또한, 빠른 학습을 위하여 tfrecord 형태로 변환하여 사용하였습니다\n","- 컴페티션 기본 데이터는 data/ 하위 폴더에 있다고 가정합니다. (train.csv, sample_submission.csv, etc)\n","- 또한 train.zip, test.zip 역시 data/ 하위에 압축을 풀어놓았다고 가정하고 시작하겠습니다.."]},{"cell_type":"code","metadata":{"id":"xKGB5-34qNaC"},"source":["# from IPython.display import clear_output\n","\n","# !add-apt-repository -y ppa:alessandro-strada/ppa; \n","# !apt-get update;\n","# !apt-get install -y google-drive-ocamlfuse;\n","# clear_output()\n","\n","# !mkdir google_drive;\n","# !google-drive-ocamlfuse -headless -label dacon_smiles -id 406775554485-vqr231cgnpofc9mkm7sr0e3uq32emf11.apps.googleusercontent.com -secret iFy1t7pKRjOzBuWHbUB-cM8V;\n","\n","# !sed -i 's/team_drive_id=0AOLSYhuNgxEsUk9PVA/team_drive_id=/' ~/.gdfuse/dacon_smiles/config\n","# !sed -i 's/team_drive_id=/team_drive_id=0AOLSYhuNgxEsUk9PVA/' ~/.gdfuse/dacon_smiles/config\n","# !google-drive-ocamlfuse -label dacon_smiles google_drive/\n","\n","# # !fusermount -u google_drive\n","\n","# # rdkit 2020.03.3 버전 다운로드\n","# !pip install kora -q\n","# import kora.install.rdkit\n","\n","# import os\n","# import os.path as pth\n","\n","# ### 저는 코랩에서 구글 드라이브를 네트워크 마운트해서 사용했기 때문에 경로가 이와 같이 됩니다.\n","# google_drive_base_path = 'google_drive/chemical/'\n","\n","# clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1UN3LYJzFgd"},"source":["import os\n","import os.path as pth\n","\n","data_base_path = 'data'\n","os.makedirs(data_base_path, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rltrdSeqzUPu"},"source":["# google_drive_base_path = 'google_drive/chemical/'\n","\n","CID_dataset_dir = 'CID-SMILES'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svTwVItXzagv"},"source":["# if not pth.exists(pth.join(data_base_path, CID_dataset_dir)):\n","#     os.system('cp -r {}/data/{} data'.format(google_drive_base_path, CID_dataset_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCVVTq4szcYU"},"source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","import functools\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import cv2\n","from tqdm import tqdm\n","from glob import glob\n","\n","import kora.install.rdkit\n","\n","import rdkit\n","from rdkit import Chem\n","from rdkit import DataStructs\n","from rdkit import RDLogger\n","from rdkit.Chem import Draw\n","import multiprocessing\n","\n","RDLogger.DisableLog('rdApp.*')  \n","\n","from IPython.display import clear_output\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s646shp96x4d"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FJ47kd1F3s9f"},"source":["## 1. CID-SMILES에서 새로운 train set 추출하기"]},{"cell_type":"markdown","metadata":{"id":"hpY0Fqdt3_jO"},"source":["먼저 Pubchem에서 다운 받은 CID-SMILES 파일을 불러온 후 1억 개의 SMILES 분자식을 text라는 변수에 하나의 스트링으로 저장합니다.  \n","이후에 진행되는 프로세스는 데이콘에서 공유해주신 것과 동일합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"bvmEQusd3-1s"},"source":["# CID-SMILES 파일 경로\n","path = pth.join(data_base_path, CID_dataset_dir, 'CID-SMILES')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sMqn5Yi4GKz"},"source":["f = open(path)\n","\n","text = \"\"\n","for _ in tqdm(range(100000000)):\n","    s = f.readline()\n","    s = s.split('\\t')[1]\n","    s = s.split('\\n')[0]\n","    text+=s\n","\n","chars = list(set(text))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RA0adQw4ghP"},"source":["char_count = {}\n","for char in tqdm(chars):\n","    char_count[char] = text.count(char)\n","char_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkhzSB7I4pA9"},"source":["pass_chars = []\n","for char,_ in sorted(char_count.items(), key=lambda x:x[1], reverse=False)[:len(char_count)//2]:\n","    pass_chars.append(char)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYx53PJ042Rh"},"source":["del(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ang0d3Kk5ZGX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adeHU7Ap5WRQ"},"source":["1.1. 더 많은 데이터를 학습하기 위해, 기존 CID-SMILES 데이터셋에서 새로운 데이터 100만개를 새로 생성합니다.\n"]},{"cell_type":"code","metadata":{"id":"B9nZ9c5t42Gn"},"source":["f = open(path)\n","\n","data = \"\"\n","for _ in tqdm(range(100000000)):\n","    s = f.readline()\n","    data+=s\n","\n","data = data.split('\\n')\n","print(len(data))\n","random.shuffle(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc2_9aiQ5F-m"},"source":["max_length = 70\n","sample_n = 1000000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fjhjyb0n5HYc"},"source":["### Original code\n","smiles_dict = {'SMILES':[]}\n","for i, d in tqdm(enumerate(data)):\n","    smiles = d.split('\\t')[1]\n","    m = Chem.MolFromSmiles(smiles)\n","    if m != None and len(smiles) <= max_length:\n","        confirm = 1\n","        for pass_char in pass_chars:\n","            if smiles.find(pass_char) != -1:\n","                confirm = 0\n","        if confirm == 1:\n","            smiles_dict['SMILES'].append(smiles)\n","    if len(smiles_dict['SMILES']) == sample_n:\n","        break\n","        \n","len(smiles_dict['SMILES'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_8wzB5b5kow"},"source":["train_another = pd.DataFrame(smiles_dict)\n","train_another['file_name'] = 'train_another_' + train_another.index.astype('str') + '.png'\n","train_another = train_another[['file_name', 'SMILES']]\n","train_another.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vtcPUkg5nhX"},"source":["train_another['SMILES'].str.len().hist(bins=20, rwidth=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XE7P9lc5qIN"},"source":["# train_another.to_csv(pth.join(google_drive_base_path, 'data', 'train_another.csv'), index=False)\n","train_another.to_csv(pth.join(data_base_path, 'train_another.csv'), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQCRzjy-68c_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDvSApTf7E6i"},"source":["1.2. 모델이 더 긴 데이터도 학습할 수 있게 길이가 70~98인 데이터도 30만개도 추가로 생성합니다.  \n","(양 끝에 '<', '>'가 추가되는 것을 고려)"]},{"cell_type":"code","metadata":{"id":"XSmzbTrl7BVt"},"source":["max_length = 98\n","sample_n = 300000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gB-Mvy1FRYS6"},"source":["smiles_dict = {'SMILES':[]}\n","for i, d in tqdm(enumerate(data)):\n","    smiles = d.split('\\t')[1]\n","    m = Chem.MolFromSmiles(smiles)\n","    if m != None and len(smiles) <= max_length and len(smiles) > 70:\n","        confirm = 1\n","        for pass_char in pass_chars:\n","            if smiles.find(pass_char) != -1:\n","                confirm = 0\n","        if confirm == 1:\n","            smiles_dict['SMILES'].append(smiles)\n","    if len(smiles_dict['SMILES']) == sample_n:\n","        break\n","        \n","len(smiles_dict['SMILES'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f2DfwOePl8y"},"source":["train_over70 = pd.DataFrame(smiles_dict)\n","train_over70['file_name'] = 'train_over70_' + train_over70.index.astype('str') + '.png'\n","train_over70 = train_over70[['file_name', 'SMILES']]\n","train_over70.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOV_e6aaSTXd"},"source":["train_over70['SMILES'].str.len().hist(bins=20, rwidth=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Wqtl52uSU27"},"source":["# train_over70.to_csv(pth.join(google_drive_base_path, 'data', 'train_over70.csv'), index=False)\n","train_over70.to_csv(pth.join(data_base_path, 'train_over70.csv'), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2HT4DgRSZaq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0V4Xw2uSUvs"},"source":["1.3. 모델이 더 다양한 데이터도 학습할 수 있게 빈도에 관계없이 길이가 ~98인 데이터도 30만개도 추가로 생성합니다.  "]},{"cell_type":"code","metadata":{"id":"nmbHLdTTSnmJ"},"source":["max_length = 98\n","sample_n = 300000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Em7UjCs7SqM7"},"source":["smiles_dict = {'SMILES':[]}\n","for i, d in tqdm(enumerate(data), position=0, leave=True):\n","    if len(d) == 0:\n","      continue\n","    smiles = d.split('\\t')[1]\n","    m = Chem.MolFromSmiles(smiles)\n","    if m != None and len(smiles) <= max_length:\n","        for pass_char in pass_chars:\n","            if pass_char in smiles:\n","                smiles_dict['SMILES'].append(smiles)\n","                break\n","    if len(smiles_dict['SMILES']) == sample_n:\n","        break\n","        \n","len(smiles_dict['SMILES'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VnRRnTfSr2B"},"source":["train_under_50per = pd.DataFrame(smiles_dict)\n","train_under_50per['file_name'] = 'train_under_50per_' + train_under_50per.index.astype('str') + '.png'\n","train_under_50per = train_under_50per[['file_name', 'SMILES']]\n","train_under_50per.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Y_ARRtkStZW"},"source":["train_under_50per['SMILES'].str.len().hist(bins=20, rwidth=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AzldYKSfSwf4"},"source":["# train_under_50per.to_csv(pth.join(google_drive_base_path, 'data', 'train_under_50per.csv'), index=False\n","train_under_50per.to_csv(pth.join(data_base_path, 'train_under_50per.csv'), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVyAyFQITOuR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tCGYqHqZbnsr"},"source":["tfrecord로 만들기 전에, 먼저 추출한 smiles 식들을 이미지로 저장합니다."]},{"cell_type":"code","metadata":{"id":"3dyKQwkkTOjY"},"source":["name_list = ['train_another', 'train_over70', 'train_under_50per']\n","for target_name in name_list:\n","    train = pd.read_csv(pth.join(data_base_path, target_name+'.csv'))\n","    print(train.shape)\n","    train_list = []\n","    for i in tqdm(range(train.shape[0]//10000+1)):\n","        train_list.append(np.array(train.loc[10000*i:10000*i+10000-1, ['SMILES', 'file_name']]))\n","    if not (os.path.isdir(target_name)):\n","        os.makedirs(os.path.join(target_name))\n","        \n","        \n","#     cpu_n = os.cpu_count()\n","    cpu_n = 16\n","\n","    error_smiles = []\n","    def f(d):\n","        s, filename = d\n","\n","        #예외 처리\n","        try:\n","            m = Chem.MolFromSmiles(s)\n","            img = Draw.MolToImage(m, size=(300,300))\n","            img = np.array(img)\n","            cv2.imwrite(pth.join(data_base_path, target_name, filename), img)\n","        except:\n","            error_smiles.append(s)\n","\n","    for t in tqdm(train_list):\n","        if __name__ == '__main__':\n","            pool = multiprocessing.Pool(processes=cpu_n)\n","            pool.map(f,t)\n","            pool.close()\n","            pool.join()        \n","            \n","    for smiles in error_smiles:\n","        train = train[train['SMILES']!=smiles]\n","        \n","    #저장\n","    train.to_csv(pth.join(data_base_path, target_name+'.csv'), index=False)        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RNRNSGtb1Xj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9_IpZPsdFOj"},"source":["## 2. 추출한 csv와 생성한 이미지를 기반으로 tfrecord 생성"]},{"cell_type":"markdown","metadata":{"id":"qNkMHhTRdken"},"source":["데이터를 읽는 오버헤드를 줄이기 위해 학습 데이터를 tfrecord형태로 새로 생성합니다"]},{"cell_type":"code","metadata":{"id":"Q9-4T5OMcy1R"},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import cv2\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, GroupKFold\n","from sklearn.utils import shuffle\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import os.path as pth\n","import shutil\n","import time\n","from tqdm import tqdm\n","\n","import numpy as np\n","from PIL import Image\n","\n","import rdkit\n","from rdkit import Chem\n","from rdkit.Chem import Draw\n","from rdkit import DataStructs\n","from rdkit import RDLogger\n","RDLogger.DisableLog('rdApp.*')  \n","\n","\n","from IPython.display import clear_output\n","\n","from multiprocessing import Process, Queue\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5HgyCFrfSU5"},"source":["def calc_max_length(tensor):\n","    return max(len(t) for t in tensor)\n","\n","\n","def cvt_mol_caption(smiles_str):\n","    smiles_str = smiles_str[1:-1]\n","    chem_mol = Chem.MolFromSmiles(str(smiles_str))\n","    converted_smile_str = Chem.MolToSmiles(\n","        chem_mol,\n","        isomericSmiles=False, # Default: True,\n","        kekuleSmiles=False, # Default: False,\n","    #     rootedAtAtom=-1,\n","    #     canonical=False,\n","        allBondsExplicit=False,\n","        allHsExplicit=False\n","    )\n","#     print(smiles_str)\n","#     print(converted_smile_str)\n","#     print()\n","    converted_smile_str = '<'+converted_smile_str+'>'\n","    return converted_smile_str\n","\n","\n","def _bytes_feature(value):\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _floatarray_feature(array):\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=array))\n","\n","def _int64_feature(value):\n","    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def _validate_text(text):\n","    \"\"\"If text is not str or unicode, then try to convert it to str.\"\"\"\n","    if isinstance(text, str):\n","        return text\n","    elif isinstance(text, 'unicode'):\n","        return text.encode('utf8', 'ignore')\n","    else:\n","        return str(text)\n","\n","\n","def to_tfrecords(image_list, label_list, label_origin_list, tfrecords_name):\n","    print(\"Start converting\")\n","    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n","    with tf.io.TFRecordWriter(path=pth.join(tfrecords_name+'.tfrecords'), options=options) as writer:\n","        for image_path, label, label_origin in tqdm(zip(image_list, label_list, label_origin_list), total=len(image_list), position=0, leave=True):\n","\n","            filename = os.path.basename(image_path)\n","    #         image = np.array(Image.open(image_path))\n","            _binary_image = tf.io.read_file(image_path)\n","#             image = tf.image.decode_jpeg(_binary_image, channels=3)\n","    #         img = tf.dtypes.cast(img, tf.float32)\n","    #         label = Image.open(label_path)\n","    #         _binary_image = image.tobytes()\n","#             _binary_label = label.tobytes()\n","            label_100 = tf.keras.preprocessing.sequence.pad_sequences(\n","                np.array([label]), maxlen=100, padding='post'\n","            )\n","\n","            each_real = ''.join([tokenizer.index_word.get(mol_i, '') for mol_i in label_100[0]])\n","            m_real = Chem.MolFromSmiles(each_real[1:-1])\n","            if m_real == None:\n","                continue\n","\n","            string_set = tf.train.Example(features=tf.train.Features(feature={\n","    #             'height': _int64_feature(image.shape[0]),\n","    #             'width': _int64_feature(image.shape[1]),\n","                'image_raw': _bytes_feature(_binary_image),\n","                # 'label': _floatarray_feature(label),\n","                'label_100': _floatarray_feature(label_100[0]),\n","                'label_origin': _bytes_feature(label_origin.encode()),\n","    #             'std': _float_feature(image.std().astype(np.float32)),\n","                'filename': _bytes_feature(filename.encode()),\n","            }))\n","\n","            writer.write(string_set.SerializeToString())    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YV7jG6Upm7cU"},"source":["Training 때 사용할 validation을 분리합니다. (Train:0.8, Validation:0.2)  \n","그냥 train_test_split을 사용하는 것보다는 5fold 형태로 분리하여 같은 데이터를 여러번 활용할 수도 있도록 하였습니다.  \n","tokenizer 같은 경우에는 가능한 모든 글자들을 대응시켜 향후에 어떤 데이터가 추가되어도 대응할 수 있도록 하였습니다."]},{"cell_type":"code","metadata":{"id":"VD_ycFfWADtU"},"source":["tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n","all_token_list = [\n","    'c', 'C', '(', ')', '1', 'O', '=', '2', 'N', '<', '>', 'n', '[',\n","    ']', '3', '@', 'H', 'l', 'S', '-', 'F', '+', '4', 's', 'o', '#',\n","    'B', 'r', '.', '/', 'P', 'i', 'I', '5', '\\\\', 'e', 'A', 'a', 'g',\n","    '6', 'u', 't', 'T', 'M', 'b', 'K', 'Z', '8', 'd', '9', 'R', 'G',\n","    '7', 'L', 'V', 'h', 'W', 'p', 'm', 'E', 'Y', '0', 'U', 'f', 'D',\n","    'y', 'k', 'X', ' ', '^', '%', '$'\n","]\n","tokenizer.fit_on_texts(all_token_list)\n","top_k = len(tokenizer.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEoqxczVdtTx"},"source":["name_list = ['train', 'train_another', 'train_over70', 'train_under_50per']\n","for train_path in name_list:\n","    with open(pth.join(data_base_path, train_path+'.csv'), 'r') as csv_file:\n","        data = csv_file.read()\n","        \n","    all_captions = []\n","    all_img_name_vector = []\n","\n","    for line in data.split('\\n')[1:-1]:\n","        image_id, smiles = line.split(',')\n","        caption = '<' + smiles + '>'\n","    #     caption = smiles\n","        full_image_path = pth.join(train_path, image_id)\n","\n","        all_img_name_vector.append(full_image_path)\n","        all_captions.append(caption)\n","\n","    train_captions, img_name_vector = shuffle(all_captions, all_img_name_vector, random_state=42)\n","\n","    train_captions = np.array(train_captions)\n","    img_name_vector = np.array(img_name_vector)\n","\n","    converted_train_captions = []\n","    for each_caption in tqdm(train_captions, position=0, leave=True):\n","        converted_train_captions.append(cvt_mol_caption(each_caption))\n","    train_captions = np.array(converted_train_captions)\n","    # train_captions = np.array(list(map(cvt_mol_caption, train_captions)))\n","\n","    max_length = calc_max_length(train_captions)\n","    # max_length = 100\n","\n","    train_seqs = tokenizer.texts_to_sequences(train_captions)\n","    cap_vector = tf.keras.preprocessing.sequence.pad_sequences(\n","        train_seqs, maxlen=max_length, padding='post'\n","    )\n","    cap_vector = cap_vector.astype(np.float32)\n","\n","    keyword = train_path.replace('train_', '')\n","\n","    temp_img_name_vector = img_name_vector\n","    temp_train_captions = cap_vector\n","    temp_origin_captions = train_captions\n","\n","    rkf = RepeatedKFold(n_splits=5, n_repeats=1, random_state=7777)\n","    for rkf_i, (train_index, val_index) in enumerate(rkf.split(temp_img_name_vector)):\n","        fold_num = (rkf_i%5) + 1\n","        repeat_num = (rkf_i//5) + 1 \n","        \n","        if not fold_num <= 2:\n","            continue\n","\n","        img_name_train, img_name_val = temp_img_name_vector[train_index], temp_img_name_vector[val_index]\n","        cap_train, cap_val = temp_train_captions[train_index], temp_train_captions[val_index]\n","        cap_origin_train, cap_origin_val = temp_origin_captions[train_index], temp_origin_captions[val_index]\n","\n","        to_tfrecords(img_name_train, cap_train, cap_origin_train, pth.join(data_base_path, 'all_train_{}_fold_{:02d}'.format(keyword, fold_num)))\n","        to_tfrecords(img_name_val, cap_val, cap_origin_val, pth.join(data_base_path, 'all_val_{}_fold_{:02d}'.format(keyword, fold_num)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVal0i_Geaft"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rAdjMVdprEtS"},"source":["Testset 또한 속도를 위해 tfrecord 형태로 변환해줍니다."]},{"cell_type":"code","metadata":{"id":"7KaYuoJ_nunW"},"source":["TEST_PATH = pth.join(data_base_path, 'test')\n","\n","with open(pth.join(data_base_path, 'sample_submission.csv'), 'r') as csv_file:\n","    data = csv_file.read()\n","    \n","test_img_path = []\n","\n","for line in data.split('\\n')[1:-1]:\n","    image_id, _ = line.split(',')\n","    full_image_path = pth.join(TEST_PATH, image_id)\n","\n","    test_img_path.append(full_image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdfhWEEPep4h"},"source":["def to_tfrecords_test(image_list, label_list, tfrecords_base):\n","    print(\"Start converting\")\n","    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n","    for image_path in tqdm(image_list, total=len(image_list), position=0, leave=True):\n","        tfrecord_filename = pth.join(tfrecords_base, pth.basename(image_path).split('.')[0])\n","        with tf.io.TFRecordWriter(path=pth.join(tfrecord_filename+'.tfrecords'), options=options) as writer:\n","            filename = os.path.basename(image_path)\n","            _binary_image = tf.io.read_file(pth.join('data', 'test', image_path))\n","            label_100 = tf.keras.preprocessing.sequence.pad_sequences(\n","                np.array([label]), maxlen=100, padding='post'\n","            )\n","\n","            string_set = tf.train.Example(features=tf.train.Features(feature={\n","                'image_raw': _bytes_feature(_binary_image),\n","                # 'label_100': _floatarray_feature(label_100[0]),\n","                # 'label_origin': _bytes_feature(label_origin.encode()),\n","                'filename': _bytes_feature(filename.encode()),\n","            }))\n","\n","            writer.write(string_set.SerializeToString())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"le-EOxVmnQAf"},"source":["to_tfrecords_test(image_list=test_img_path, tfrecords_name=pth.join(data_base_path, 'test'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdkU2A6D3d14"},"source":[""],"execution_count":null,"outputs":[]}]}